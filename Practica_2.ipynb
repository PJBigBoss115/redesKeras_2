{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Segunda-práctica:-Aspectos-prácticos-de-las-redes-neuronales\" data-toc-modified-id=\"Segunda-práctica:-Aspectos-prácticos-de-las-redes-neuronales-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Segunda práctica: Aspectos prácticos de las redes neuronales</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Obtención-de-los-datos-y-pre-processing\" data-toc-modified-id=\"Obtención-de-los-datos-y-pre-processing-1.0.0.1\"><span class=\"toc-item-num\">1.0.0.1&nbsp;&nbsp;</span>Obtención de los datos y pre-processing</a></span></li></ul></li></ul></li><li><span><a href=\"#Consideraciones-iniciales\" data-toc-modified-id=\"Consideraciones-iniciales-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Consideraciones iniciales</a></span><ul class=\"toc-item\"><li><span><a href=\"#Train-validation-test-split\" data-toc-modified-id=\"Train-validation-test-split-1.1.1\"><span class=\"toc-item-num\">1.1.1&nbsp;&nbsp;</span>Train-validation-test split</a></span></li><li><span><a href=\"#Un-error-común-con-modelos-de-Keras\" data-toc-modified-id=\"Un-error-común-con-modelos-de-Keras-1.1.2\"><span class=\"toc-item-num\">1.1.2&nbsp;&nbsp;</span>Un error común con modelos de Keras</a></span></li><li><span><a href=\"#Análisis-de-resultados\" data-toc-modified-id=\"Análisis-de-resultados-1.1.3\"><span class=\"toc-item-num\">1.1.3&nbsp;&nbsp;</span>Análisis de resultados</a></span></li></ul></li><li><span><a href=\"#1.-Unidades-de-activación\" data-toc-modified-id=\"1.-Unidades-de-activación-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>1. Unidades de activación</a></span></li><li><span><a href=\"#2.-Inicialización-de-parámetros\" data-toc-modified-id=\"2.-Inicialización-de-parámetros-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>2. Inicialización de parámetros</a></span></li><li><span><a href=\"#3.-Optimizadores\" data-toc-modified-id=\"3.-Optimizadores-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>3. Optimizadores</a></span></li><li><span><a href=\"#4.-Regularización-y-red-final-(2.5-puntos)\" data-toc-modified-id=\"4.-Regularización-y-red-final-(2.5-puntos)-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>4. Regularización y red final <em>(2.5 puntos)</em></a></span><ul class=\"toc-item\"><li><span><a href=\"#Evaluación-del-modelo-en-datos-de-test\" data-toc-modified-id=\"Evaluación-del-modelo-en-datos-de-test-1.5.1\"><span class=\"toc-item-num\">1.5.1&nbsp;&nbsp;</span>Evaluación del modelo en datos de test</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ip9ysnsTFqJ"
   },
   "source": [
    "# Segunda práctica: Aspectos prácticos de las redes neuronales\n",
    "\n",
    "En esta segunda parte, vamos a continuar desarrollando el problema de Fashion MNIST, con el objetivo de entender los aspectos prácticos del entrenamiento de redes neuronales.\n",
    "\n",
    "El código utilizado para contestar tiene que quedar claramente reflejado en el Notebook. Puedes crear nuevas cells si así lo deseas para estructurar tu código y sus salidas. A la hora de entregar el notebook, **asegúrate de que los resultados de ejecutar tu código han quedado guardados**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yQ1DOKSRTFqK"
   },
   "outputs": [],
   "source": [
    "# Puedes añadir todos los imports adicionales que necesites aquí\n",
    "import keras\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lBY7qt3mTFqM"
   },
   "source": [
    "#### Obtención de los datos y pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PImY4g9yTFqM"
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zJyX2Bk8TFqO"
   },
   "source": [
    "## Consideraciones iniciales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jRmct5ogTFqO"
   },
   "source": [
    "### Train-validation-test split\n",
    "\n",
    "En todos los modelos que entrenemos, vamos a partir los datos de training (x_train) en dos sets: training y validación. De este modo, al final tendremos tres datasets distintos: training, validation, y test. Esta es una estrategia común en el aprendizaje automático, en la que los datos de test (o held-out data) se \n",
    "\"esconden\" hasta el final. Los datos de validación se utilizan para estimar cómo de bien están funcionando nuestros modelos y para observar si estamos cayendo en overfitting. Esto nos permite cambiar hiperparámetros y probar distintas arquitecturas **sabiendo que no estamos utilizando información del test set para \"optimizar\" los resultados en éste** (si eligiéramos nuestro mejor modelo en base a los resultados de test, estaríamos \"haciendo trampas\", ya que se ha utilizado la información contenida en éste para elegir el modelo y las métricas reportadas serían optimistas).\n",
    "\n",
    "Para utilizar un split training-validation data durante el entrenamiento, podemos partir nosotros mismos los datos o dejar que Keras lo haga. Podéis ver cómo hacer estas particiones en la documentación de *fit*.\n",
    "\n",
    "**Requisito: En todos los entrenamientos de esta práctica, se requiere utilizar el 20% de los datos en x_train como  conjunto de datos de validación**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BttR0CzHTFqP"
   },
   "source": [
    "### Un error común con modelos de Keras\n",
    "\n",
    "En esta práctica entrenaremos varios modelos para comparar resultados. Un error común en Keras es no instanciar un nuevo modelo cada vez que hacemos un nuevo entrenamiento. Al hacer\n",
    "\n",
    "*model = Sequential()*\n",
    "\n",
    "*model.add(lo que sea)  # Definición del modelo*\n",
    "\n",
    "*model.fit()*\n",
    "\n",
    "si queremos entrenar un nuevo modelo o el mismo modelo otra vez, es necesario volver a inicializar el modelo con model = Sequential(). Si olvidamos este paso y volvemos a hacer fit(), el modelo seguirá entrenando por donde se quedó en el último fit()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X7REMbqlTFqP"
   },
   "source": [
    "### Análisis de resultados \n",
    "\n",
    "A la hora de escribir las respuestas y los análisis pedidos, es importante presentar las conclusiones de manera adecuada a partir de lo visto en nuestros experimentos. Los Jupyter Notebook son una herramienta imprescindible para *data scientists* e ingenieros de Machine Learning para presentar los resultados, incluyendo soporte para incluir gráficas y elementos visuales. Podéis explicar vuestras observaciones del modo que consideréis adecuado, si bien recomendamos la utilización de gráficas para evaluar los entrenamientos y comparar resultados.\n",
    "\n",
    "Como ayuda, las siguientes funciones pueden resultar interesantes a la hora de evaluar resultados. Todas ellas utilizan el objeto *history* que podéis obtener como salida del método *fit()* de Keras:\n",
    "\n",
    "history = model.fit(x_train, y_train, ...)\n",
    "\n",
    "Por supuesto, podéis modificarlas y utilizarlas como prefiráis para crear vuestros propios informes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L5epQBRpTFqP"
   },
   "outputs": [],
   "source": [
    "def plot_acc(history, title=\"Model Accuracy\"):\n",
    "    \"\"\"Imprime una gráfica mostrando la accuracy por epoch obtenida en un entrenamiento\"\"\"\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title(title)\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Val'], loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "def plot_loss(history, title=\"Model Loss\"):\n",
    "    \"\"\"Imprime una gráfica mostrando la pérdida por epoch obtenida en un entrenamiento\"\"\"\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title(title)\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Val'], loc='upper right')\n",
    "    plt.show()\n",
    "    \n",
    "def plot_compare_losses(history1, history2, name1=\"Red 1\",\n",
    "                        name2=\"Red 2\", title=\"Graph title\"):\n",
    "    \"\"\"Compara losses de dos entrenamientos con nombres name1 y name2\"\"\"\n",
    "    plt.plot(history1.history['loss'], color=\"green\")\n",
    "    plt.plot(history1.history['val_loss'], 'r--', color=\"green\")\n",
    "    plt.plot(history2.history['loss'], color=\"blue\")\n",
    "    plt.plot(history2.history['val_loss'], 'r--', color=\"blue\")\n",
    "    plt.title(title)\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train ' + name1, 'Val ' + name1, \n",
    "                'Train ' + name2, 'Val ' + name2],\n",
    "               loc='upper right')\n",
    "    plt.show()\n",
    "    \n",
    "def plot_compare_accs(history1, history2, name1=\"Red 1\",\n",
    "                      name2=\"Red 2\", title=\"Graph title\"):\n",
    "    \"\"\"Compara accuracies de dos entrenamientos con nombres name1 y name2\"\"\"\n",
    "    plt.plot(history1.history['acc'], color=\"green\")\n",
    "    plt.plot(history1.history['val_acc'], 'r--', color=\"green\")\n",
    "    plt.plot(history2.history['acc'], color=\"blue\")\n",
    "    plt.plot(history2.history['val_acc'], 'r--', color=\"blue\")\n",
    "    plt.title(title)\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train ' + name1, 'Val ' + name1, \n",
    "                'Train ' + name2, 'Val ' + name2], \n",
    "               loc='lower right')\n",
    "    plt.show()\n",
    "    \n",
    "# Nota: podéis cambiar los números aquí presentes y ejecutar esta línea si queréis cambiar el tamaño\n",
    "# de las gráficas\n",
    "# matplotlib.rcParams['figure.figsize'] = [8, 8]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M_yZ9B8gTFqR"
   },
   "source": [
    "## 1. Unidades de activación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MuVNxmXSTFqR"
   },
   "source": [
    "En este ejercicio, vamos a evaluar la importancia de utilizar las unidades de activación adecuadas. Las funciones de activación como sigmoid han dejado de utilizarse en favor de otras unidades como ReLU.\n",
    "\n",
    "**Ejercicio 1 *(2.5 puntos)***: Partiendo de una red sencilla como la desarrollada en el Trabajo 1, escribir un breve análisis comparando la utilización de unidades sigmoid y ReLU (por ejemplo, se pueden comentar aspectos como velocidad de convergencia, métricas obtenidas...). Explicar por qué pueden darse estas diferencias. Opcionalmente, comparar con otras activaciones disponibles en Keras.\n",
    "\n",
    "*Pista: Usando redes más grandes se hace más sencillo apreciar las diferencias. Es mejor utilizar al menos 3 o 4 capas densas.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hoYUajTuTFqS"
   },
   "outputs": [],
   "source": [
    "# Definir y compilar el modelo que usa activación sigmoid en las capas ocultas\n",
    "model_sigmoid = Sequential([\n",
    "    Dense(128, activation='sigmoid', input_shape=(784,)),  # Capa densa con 128 neuronas y activación sigmoid\n",
    "    Dense(128, activation='sigmoid'),                      # Segunda capa densa con activación sigmoid\n",
    "    Dense(128, activation='sigmoid'),                      # Tercera capa densa con activación sigmoid\n",
    "    Dense(10, activation='softmax')                        # Capa de salida con activación softmax para clasificación\n",
    "])\n",
    "\n",
    "# Definir y compilar el modelo que usa activación ReLU en las capas ocultas\n",
    "model_relu = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(784,)),    # Capa densa con 128 neuronas y activación ReLU\n",
    "    Dense(128, activation='relu'),                        # Segunda capa densa con activación ReLU\n",
    "    Dense(128, activation='relu'),                        # Tercera capa densa con activación ReLU\n",
    "    Dense(10, activation='softmax')                       # Capa de salida con activación softmax para clasificación\n",
    "])\n",
    "\n",
    "model_sigmoid.compile(optimizer='adam',                   # Usar el optimizador Adam para el ajuste automático del aprendizaje\n",
    "                      loss='sparse_categorical_crossentropy',  # Función de pérdida para clasificación de múltiples clases\n",
    "                      metrics=['accuracy'])                # Seguimiento de la precisión del modelo durante el entrenamiento\n",
    "model_relu.compile(optimizer='adam',                     # Usar el optimizador Adam para el ajuste automático del aprendizaje\n",
    "                   loss='sparse_categorical_crossentropy',  # Función de pérdida para clasificación de múltiples clases\n",
    "                   metrics=['accuracy'])                  # Seguimiento de la precisión del modelo durante el entrenamiento\n",
    "\n",
    "# Entrenar ambos modelos y guardar el historial para análisis posterior\n",
    "history_sigmoid = model_sigmoid.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test), verbose=0)\n",
    "history_relu = model_relu.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test), verbose=0)\n",
    "\n",
    "# Visualizar resultados\n",
    "plot_compare_accs(history_sigmoid, history_relu, name1=\"Sigmoid\", name2=\"ReLU\", title=\"Accuracy Comparison: Sigmoid vs ReLU\")\n",
    "plot_compare_losses(history_sigmoid, history_relu, name1=\"Sigmoid\", name2=\"ReLU\", title=\"Loss Comparison: Sigmoid vs ReLU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ReLU vs. Sigmoid:\n",
    "ReLU generalmente converge más rápido y proporciona mejores resultados en redes profundas debido a la menor probabilidad de que ocurra el problema de desvanecimiento de gradiente en comparación con la función sigmoid.\n",
    "#### Visualización: \n",
    "Las gráficas mostrarán cómo los modelos con ReLU pueden comenzar a aprender más rápido y alcanzar una mayor precisión en comparación con sigmoid, que puede sufrir de saturación de neuronas especialmente en las capas más profundas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pu6RbUFKTFqT"
   },
   "source": [
    "## 2. Inicialización de parámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Abmm05UPTFqU"
   },
   "source": [
    "En este ejercicio, vamos a evaluar la importancia de una correcta inicialización de parámetros en una red neuronal.\n",
    "\n",
    "**Ejercicio 2 *(2.5 puntos)***: Partiendo de una red similar a la del ejercicio anterior (usando ya ReLUs), comentar las diferencias que se aprecian en el entrenamiento al utilizar distintas estrategias de inicialización de parámetros. Para ello, inicializar todas las capas con las siguientes estrategias, disponibles en Keras, y analizar sus diferencias:\n",
    "\n",
    "* Inicialización con ceros.\n",
    "* Inicialización con una variable aleatoria normal.\n",
    "* Inicialización con los valores por defecto de Keras para una capa Dense (estrategia *glorot uniform*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qcMt7pSkTFqU"
   },
   "outputs": [],
   "source": [
    "# Inicializadores\n",
    "zero_initializer = Zeros()\n",
    "# Variable aleatoria normal\n",
    "normal_initializer = RandomNormal()\n",
    "# Inicializacion con los valores por defecto (Estrategia Glorot Uniform)\n",
    "glorot_initializer = GlorotUniform()\n",
    "\n",
    "# Modelos con diferentes inicializaciones\n",
    "model_zeros = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(784,), kernel_initializer=zero_initializer),\n",
    "    Dense(128, activation='relu', kernel_initializer=zero_initializer),\n",
    "    Dense(128, activation='relu', kernel_initializer=zero_initializer),\n",
    "    Dense(10, activation='softmax', kernel_initializer=zero_initializer)\n",
    "])\n",
    "\n",
    "model_normal = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(784,), kernel_initializer=normal_initializer),\n",
    "    Dense(128, activation='relu', kernel_initializer=normal_initializer),\n",
    "    Dense(128, activation='relu', kernel_initializer=normal_initializer),\n",
    "    Dense(10, activation='softmax', kernel_initializer=normal_initializer)\n",
    "])\n",
    "\n",
    "model_glorot = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(784,), kernel_initializer=glorot_initializer),\n",
    "    Dense(128, activation='relu', kernel_initializer=glorot_initializer),\n",
    "    Dense(128, activation='relu', kernel_initializer=glorot_initializer),\n",
    "    Dense(10, activation='softmax', kernel_initializer=glorot_initializer)\n",
    "])\n",
    "\n",
    "# Compilación de modelos\n",
    "model_zeros.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model_normal.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model_glorot.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Entrenamiento de modelos\n",
    "history_zeros = model_zeros.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test), verbose=0)\n",
    "history_normal = model_normal.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test), verbose=0)\n",
    "history_glorot = model_glorot.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test), verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NqIAyVWrTFqV"
   },
   "source": [
    "## 3. Optimizadores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lcYj29hYTFqW"
   },
   "source": [
    "**Ejercicio 3 *(2.5 puntos)***: Partiendo de una red similar a la del ejercicio anterior (utilizando la mejor estrategia de inicialización observada), comparar y analizar las diferencias que se observan  al entrenar con varios de los optimizadores vistos en clase, incluyendo SGD como optimizador básico (se puede explorar el espacio de hiperparámetros de cada optimizador, aunque para optimizadores más avanzados del estilo de adam y RMSprop es buena idea dejar los valores por defecto provistos por Keras)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0fWDiqXvTFqW"
   },
   "outputs": [],
   "source": [
    "# Inicializador Glorot Uniform\n",
    "initializer = GlorotUniform()\n",
    "\n",
    "# Configuración de optimizadores\n",
    "optimizers = {\n",
    "    'SGD': SGD(learning_rate=0.01, momentum=0.9),\n",
    "    'Adam': Adam(),\n",
    "    'RMSprop': RMSprop()\n",
    "}\n",
    "\n",
    "histories = {}\n",
    "\n",
    "# Crear, compilar y entrenar modelos para cada optimizador\n",
    "for name, optimizer in optimizers.items():\n",
    "    model = Sequential([\n",
    "        Dense(128, activation='relu', input_shape=(784,), kernel_initializer=initializer),\n",
    "        Dense(128, activation='relu', kernel_initializer=initializer),\n",
    "        Dense(128, activation='relu', kernel_initializer=initializer),\n",
    "        Dense(10, activation='softmax', kernel_initializer=initializer)\n",
    "    ])\n",
    "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    histories[name] = model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test), verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BkfTFoJOTFqZ"
   },
   "source": [
    "## 4. Regularización y red final *(2.5 puntos)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f6CQhK7ZTFqZ"
   },
   "source": [
    "**Ejercicio 4.1**: Entrenar una red final que sea capaz de obtener una accuracy en el validation set cercana al 90%. Para ello, combinar todo lo aprendido anteriormente y utilizar técnicas de regularización para evitar overfitting. Algunos de los elementos que pueden tenerse en cuenta son los siguientes.\n",
    "\n",
    "* Número de capas y neuronas por capa\n",
    "* Optimizadores y sus parámetros\n",
    "* Batch size\n",
    "* Unidades de activación\n",
    "* Uso de capas dropout, regularización L2, regularización L1...\n",
    "* Early stopping (se puede aplicar como un callback de Keras, o se puede ver un poco \"a ojo\" cuándo el modelo empieza a caer en overfitting y seleccionar el número de epochs necesarias)\n",
    "* Batch normalization\n",
    "\n",
    "Si los modelos entrenados anteriormente ya se acercaban al valor requerido de accuracy, probar distintas estrategias igualmente y comentar los resultados.\n",
    "\n",
    "Explicar brevemente la estrategia seguida y los modelos probados para obtener el modelo final, que debe verse entrenado en este Notebook. No es necesario guardar el entrenamiento de todos los modelos que se han probado, es suficiente con explicar cómo se ha llegado al modelo final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AUJ5AtunTFqa"
   },
   "outputs": [],
   "source": [
    "# Inicialización del modelo utilizando la API Sequential de Keras.\n",
    "model = Sequential([\n",
    "    # Capa densa con 512 neuronas y función de activación ReLU. \n",
    "    # Utiliza la inicialización GlorotUniform, adecuada para mantener la varianza de los outputs.\n",
    "    Dense(512, activation='relu', input_shape=(784,), kernel_initializer=GlorotUniform()),\n",
    "    BatchNormalization(),  # Normaliza la activación de la capa anterior, estabilizando el aprendizaje.\n",
    "    Dropout(0.3),  # Aplica dropout al 30% de las neuronas, para reducir el overfitting.\n",
    "    Dense(256, activation='relu', kernel_initializer=GlorotUniform()),  # Segunda capa densa con 256 neuronas.\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(128, activation='relu', kernel_initializer=GlorotUniform()),  # Tercera capa densa con 128 neuronas.\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(10, activation='softmax', kernel_initializer=GlorotUniform())  # Capa de salida con 10 clases.\n",
    "])\n",
    "\n",
    "# Compilación del modelo especificando el optimizador Adam, la función de pérdida y la métrica de precisión.\n",
    "model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Configuración de EarlyStopping para monitorear la precisión de validación y detener el entrenamiento\n",
    "# si no hay mejora después de 5 épocas, restaurando los mejores pesos encontrados.\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Entrenamiento del modelo con datos de entrenamiento y validación, utilizando el callback de EarlyStopping.\n",
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=50,  # Número máximo de épocas.\n",
    "    batch_size=64,  # Tamaño del lote.\n",
    "    validation_data=(x_test, y_test),\n",
    "    callbacks=[early_stopping],  # Lista de callbacks.\n",
    "    verbose=2  # Modo de verbosidad 2, que muestra una línea por época.\n",
    ")\n",
    "\n",
    "# Visualización del desempeño del modelo.\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Performance')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estrategia para el Modelo Final\n",
    "+ Número de capas y neuronas: Utilizar una estructura profunda con suficientes neuronas para capturar la complejidad del problema sin caer en overfitting.\n",
    "\n",
    "+ Optimizadores: Basándonos en experimentos anteriores, emplearemos Adam por su eficiencia y adaptabilidad.\n",
    "\n",
    "+ Batch size: Ajustar el tamaño del lote para equilibrar la velocidad de entrenamiento y la estabilidad del aprendizaje.\n",
    "\n",
    "+ Unidades de Activación: ReLU se ha mostrado eficaz en capas ocultas por su capacidad para mitigar el problema del gradiente desvanecido.\n",
    "\n",
    "+ Regularización: Incorporar Dropout para reducir el overfitting al añadir aleatoriedad durante el entrenamiento. Además, la Batch Normalization ayuda a normalizar las entradas de cada capa, acelerando la convergencia.\n",
    "\n",
    "+ Early Stopping: Utilizar como un callback para detener el entrenamiento cuando el rendimiento en el conjunto de validación deje de mejorar, evitando así el overfitting.\n",
    "\n",
    "+ Batch Normalization: Aplicarla después de cada capa densa para estabilizar el aprendizaje y mejorar el rendimiento.\n",
    "\n",
    "#### Explicación del Modelo Final\n",
    "Capas densas con más neuronas en la primera capa, decreciendo el número en capas subsiguientes para formar una estructura de embudo que ayuda a concentrar la información relevante.\n",
    "\n",
    "Dropout y Batch Normalization después de cada capa para regularizar y mejorar la eficiencia del entrenamiento.\n",
    "\n",
    "Early Stopping para cortar el entrenamiento si el modelo deja de mejorar, lo cual protege contra el overfitting y optimiza los recursos computacionales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B5LcQgwUTFqb"
   },
   "source": [
    "### Evaluación del modelo en datos de test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ldy0NmtTFqb"
   },
   "source": [
    "Una vez elegido el que creemos que es nuestro mejor modelo a partir de la estimación que hemos visto en los datos de validación, es hora de utilizar los datos de test para ver cómo se comporta nuestro modelo ante nuevos datos. Si hemos hecho bien las cosas, este número debería ser parecido al valor de nuestra estimación vista en los datos de validación.\n",
    "\n",
    "**Pregunta 4.2**. Utilizando nuestro mejor modelo, obtener la accuracy resultante en el dataset de test. Comentar este resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1AchhaHqTFqc"
   },
   "outputs": [],
   "source": [
    "# Evaluación del modelo en el conjunto de test\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "# Impresión de la precisión obtenida en el conjunto de test\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Comparación con la precisión en validación\n",
    "val_accuracy = max(history.history['val_accuracy'])  # Mejor precisión de validación durante el entrenamiento\n",
    "print(f\"Best Validation Accuracy: {val_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comentarios sobre los resultados\n",
    "1. Precisión en el Test vs. Validación: El resultado de la precisión en el conjunto de test debería ser comparado con la mejor precisión observada en el conjunto de validación. Si ambos valores son cercanos, indica que el modelo ha generalizado bien y no ha sufrido de overfitting significativo.\n",
    "\n",
    "2. Discrepancia entre Test y Validación: Una gran diferencia entre estas métricas podría sugerir problemas como:\n",
    "\n",
    "    + Overfitting al conjunto de validación: Esto puede ocurrir si el conjunto de validación no es representativo del conjunto general de datos o si se ha realizado una optimización excesiva en las decisiones de modelado basadas en este conjunto.\n",
    "    + Underfitting: Si ambos, la precisión del test y la validación son bajas, el modelo podría no ser suficientemente complejo o bien entrenado para capturar las regularidades en los datos.\n",
    "3. Expectativas Realistas: Es importante recordar que la precisión en el mundo real puede ser menor que la observada durante el entrenamiento y las pruebas, especialmente si existen diferencias en la distribución de los datos entre el ambiente de entrenamiento/testeo y la aplicación real."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Actividad_1_Parte_2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
